{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satya/Anaconda/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import tree\n",
    "import collections\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import datetime, time\n",
    "import pytz\n",
    "import statsmodels.api as stats_api\n",
    "import pickle as pickle_\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Popularity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtags = ['#gopatriots','#nfl','#sb49','#gohawks','#patriots','#superbowl'] #using only one tag\n",
    "#hashtags = ['#sb49','#gohawks','#patriots','#superbowl'] #using only one tag\n",
    "df_map = {} # to store dfs for each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading files into dataframes and storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  #gopatriots\n",
      "0\n",
      "20000\n",
      "Processing  #nfl\n",
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "Processing  #sb49\n",
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "260000\n",
      "280000\n",
      "300000\n",
      "320000\n",
      "340000\n",
      "360000\n",
      "380000\n",
      "400000\n",
      "420000\n",
      "440000\n",
      "460000\n",
      "480000\n",
      "500000\n",
      "520000\n",
      "540000\n",
      "560000\n",
      "580000\n",
      "600000\n",
      "620000\n",
      "640000\n",
      "660000\n",
      "680000\n",
      "700000\n",
      "720000\n",
      "740000\n",
      "760000\n",
      "780000\n",
      "800000\n",
      "820000\n",
      "Processing  #gohawks\n",
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "Processing  #patriots\n",
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "260000\n",
      "280000\n",
      "300000\n",
      "320000\n",
      "340000\n",
      "360000\n",
      "380000\n",
      "400000\n",
      "420000\n",
      "440000\n",
      "460000\n",
      "480000\n",
      "Processing  #superbowl\n",
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "260000\n",
      "280000\n",
      "300000\n",
      "320000\n",
      "340000\n",
      "360000\n",
      "380000\n",
      "400000\n",
      "420000\n",
      "440000\n",
      "460000\n",
      "480000\n",
      "500000\n",
      "520000\n",
      "540000\n",
      "560000\n",
      "580000\n",
      "600000\n",
      "620000\n",
      "640000\n",
      "660000\n",
      "680000\n",
      "700000\n",
      "720000\n",
      "740000\n",
      "760000\n",
      "780000\n",
      "800000\n",
      "820000\n",
      "840000\n",
      "860000\n",
      "880000\n",
      "900000\n",
      "920000\n",
      "940000\n",
      "960000\n",
      "980000\n",
      "1000000\n",
      "1020000\n",
      "1040000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "df_columns = ['timestamp','tweet_id','author_id','followers','retweets','title','location']\n",
    "bypass = False\n",
    "for hashtag in hashtags:\n",
    "    df = pd.DataFrame(columns=df_columns)\n",
    "    lno = 0\n",
    "    print(\"Processing \",hashtag)\n",
    "    with open(\"tweet_data/tweets_\"+hashtag+\".txt\", \"r\") as file_obj:\n",
    "        if(not os.path.isfile('temp/'+hashtag+'.csv') or bypass):\n",
    "            writer=csv.writer(open('temp/'+hashtag+'.csv','w'))\n",
    "            writer.writerow(df_columns)\n",
    "            line = file_obj.readline()\n",
    "            while(line):\n",
    "                if(lno%20000 == 0):\n",
    "                    print(lno)\n",
    "                j = json.loads(line)\n",
    "                lno+=1\n",
    "                timestamp =j['citation_date']\n",
    "                followers =j['author']['followers']\n",
    "                retweets = j['metrics']['citations']['total']\n",
    "                author_id = j['author']['url']\n",
    "                tweet_id = j['tweet']['id']\n",
    "                title = j['title']\n",
    "                location=j['tweet']['user']['location']\n",
    "                writer.writerow([timestamp,tweet_id,author_id,followers,retweets,title,location])\n",
    "                line = file_obj.readline()\n",
    "        else:\n",
    "            print(\"File Exists!\")\n",
    "            #writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataframe #gopatriots\n",
      "loaded dataframe #nfl\n",
      "loaded dataframe #sb49\n",
      "loaded dataframe #gohawks\n",
      "loaded dataframe #patriots\n",
      "loaded dataframe #superbowl\n"
     ]
    }
   ],
   "source": [
    "for hashtag in hashtags:\n",
    "    print('loaded dataframe',hashtag)\n",
    "    df_map[hashtag] = pd.read_csv('temp/'+hashtag+'.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#gopatriots\n",
      "timestamp    26232\n",
      "tweet_id     26232\n",
      "author_id    26232\n",
      "followers    26232\n",
      "retweets     26232\n",
      "dtype: int64\n",
      "#nfl\n",
      "timestamp    259024\n",
      "tweet_id     259024\n",
      "author_id    259024\n",
      "followers    259024\n",
      "retweets     259024\n",
      "dtype: int64\n",
      "#sb49\n",
      "timestamp    826951\n",
      "tweet_id     826951\n",
      "author_id    826951\n",
      "followers    826951\n",
      "retweets     826951\n",
      "dtype: int64\n",
      "#gohawks\n",
      "timestamp    188136\n",
      "tweet_id     188136\n",
      "author_id    188136\n",
      "followers    188136\n",
      "retweets     188136\n",
      "dtype: int64\n",
      "#patriots\n",
      "timestamp    489713\n",
      "tweet_id     489713\n",
      "author_id    489713\n",
      "followers    489713\n",
      "retweets     489713\n",
      "dtype: int64\n",
      "#superbowl\n",
      "timestamp    1348762\n",
      "tweet_id     1348762\n",
      "author_id    1348762\n",
      "followers    1348762\n",
      "retweets     1348762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for hashtag in hashtags:\n",
    "    print(hashtag)\n",
    "    df = df_map[hashtag]\n",
    "    print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_hrly = {}\n",
    "retweets_hrly = {}\n",
    "followers_hrly = {}\n",
    "tweets_cnt = {}\n",
    "retweets_cnt = {}\n",
    "followers_cnt = {}\n",
    "\n",
    "for hashtag in hashtags:\n",
    "    print(hashtag)\n",
    "    print(1)\n",
    "    df = df_map[hashtag]\n",
    "    print(2)\n",
    "    sec = df['timestamp'].max() - df['timestamp'].min()   \n",
    "    print(3)\n",
    "    tweets_cnt[hashtag] = df['tweet_id'].count()\n",
    "    print(4)\n",
    "    retweets_cnt[hashtag] = df['retweets'].sum()\n",
    "    print(5)\n",
    "    followers_cnt[hashtag] = df['followers'].sum()\n",
    "    print(6)\n",
    "    tweets_hrly[hashtag] = (tweets_cnt[hashtag]*3600)/sec\n",
    "    print(7)\n",
    "    retweets_hrly[hashtag] = (retweets_cnt[hashtag]*3600)/sec\n",
    "    print(8)\n",
    "    followers_hrly[hashtag] = (followers_cnt[hashtag]*3600)/sec    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Tweets Count : ',tweets_cnt)\n",
    "print('Tweets Avg. hourly',tweets_hrly)\n",
    "print('Retweets Count : ',retweets_cnt)\n",
    "print('Retweets Avg. hourly',retweets_hrly)\n",
    "\n",
    "print('Followers Count : ',followers_cnt)\n",
    "print('Followers Avg. hourly',followers_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold cross validation from our previous project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_10fold(X,y,regressor, print_ = False,shuffle_= True):\n",
    "    kf = KFold(n_splits=10,shuffle=shuffle_, random_state=0)\n",
    "    i = 1\n",
    "    bestModel = None\n",
    "    tr_e = 0\n",
    "    ts_e = 0\n",
    "    min_ts_e = 10\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        regressor.fit(X_train,y_train)\n",
    "        train_preds = regressor.predict(X_train)\n",
    "        test_preds = regressor.predict(X_test)\n",
    "        test_error = mean_squared_error(y_test,test_preds)\n",
    "        tr_e += mean_squared_error(y_train,train_preds)\n",
    "        ts_e += test_error\n",
    "        if(print_):\n",
    "            print(\"Fold : \",i)\n",
    "            print(\"Training RMSE : \",np.sqrt(mean_squared_error(y_train,train_preds)))\n",
    "            print(\"Test RMSE : \",np.sqrt(test_error))\n",
    "        if(test_error<min_ts_e):\n",
    "            min_ts_e = test_error\n",
    "            bestModel = regressor\n",
    "        i = i+1\n",
    "    return np.sqrt(tr_e/10),np.sqrt(ts_e/10), bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns the hour number from timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pst_tz = pytz.timezone('US/Mountain')\n",
    "def getHourofDay(timestamp):\n",
    "    #print(timestamp)\n",
    "    return datetime.datetime.fromtimestamp(timestamp, pst_tz).hour\n",
    "\n",
    "    \n",
    "def getHour(timestamp):\n",
    "    return int(timestamp/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_map = {}\n",
    "Y_map = {}\n",
    "for hashtag in hashtags:\n",
    "    print(hashtag)\n",
    "    df = df_map[hashtag].copy()\n",
    "    df['timestamp'] = df['timestamp'].apply(lambda x:getHour(x) )\n",
    "    grouped = df.groupby('timestamp').agg({'followers': ['sum', 'max'],'tweet_id':'count', 'retweets':'sum'})\n",
    "    grouped.columns = [\"_\".join(x) for x in grouped.columns.ravel()]\n",
    "    #grouped.columns=grouped.columns.droplevel()\n",
    "    grouped.reset_index(inplace=True)\n",
    "    grouped['hour_of_day','tweet'] = grouped.apply(lambda x: getHourofDay(x['timestamp']*3600), axis=1)\n",
    "    X_map[hashtag] = grouped.drop(['timestamp','tweet_id_count'],axis=1)\n",
    "    Y_map[hashtag] = grouped['tweet_id_count']\n",
    "    #print(grouped)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for hashtag in hashtags:\n",
    "    print(hashtag)\n",
    "    model = stats_api.OLS(Y_map['#gopatriots'],X_map['#gopatriots']).fit()\n",
    "    print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
